y.train[i,10] = 2
}
else
{
g = substr(y.train[i, ]$Group, 3, 5 )
if (g == "di") {
y.train[i, 10] = 1
}
else {
y.train[i, 10] = 0
}
}
}
##subset data to test set with the remaining rows (rows that do not have manual classes)
y.test = y[which(y$Group == "")[1]:nrow(y),]
##factoring data tells R that the values are categorical data
y.train$Group = factor(y.train$Group)
y.train$Group.detail  = NULL
y.train$V10 = factor(y.train$V10)
##set seed for randomforest
set.seed(10)
##store classes for training data
dfg = y.train$V10
chelix = y.train$Group
##create training data for DFG classification based on only p1p1x and p2p2x
y.dfg = y.train
y.dfg[,c(1,2,3,4,7,8)]= NULL
## imput null/missing data using columns 2:9 to predict chelix classes
y.train.rf.impute = rfImpute(
x = y.train[,c(2:10)],
y = y.train$Group ,
ntree = 1000)
#y.train.rf.impute.2 =  y.train.rf.impute[c(2:9)]
colnames(y.train.rf.impute)[1] <- 'Group'
y.train.rf.impute.2$V10 = y.train$V10
## Use all columns to train a DFG classifier
y.train.rf.dfg = randomForest( V10 ~., data=y.train.rf.impute.2,
ntree = 1000)
y.train.rf.impute.2$Group = as.factor(y.train$Group)
## train Chelix predictor
y.train.rf = randomForest(Group ~.,data = y.train.rf.impute.2,
ntree = 1000)
##remove first two columns in test set (empty since no classes)
y.test[c(1)]= NULL
##remove rows with null data
y.test = y.test[complete.cases(y.test),]
##predict DFG status for test set
y.train.rf.dfg
y.train.rf.dfg$importance
y = read.table("../../1_manual_classes/x_old/stdy_kinase.param.170825.rrahman.csv", sep = ",", header = T)
row.names(y) = y$pdb_id
y$pdb_id = NULL
y$pdb_id.1 = NULL
y = y[,c(2,4,5,6,7,8,10,11,13)]
y.train = y[c(1,3:265),]
y.train = y[which(y$Group != ""),]
for (i in 1:nrow(y.train))
{
if (y.train[i, ]$Group == "other")
{
y.train[i,10] = 2
}
else
{
g = substr(y.train[i, ]$Group, 3, 5 )
if (g == "di") {
y.train[i, 10] = 1
}
else {
y.train[i, 10] = 0
}
}
}
y.test = y[which(y$Group == "")[1]:nrow(y),]
y.train$Group = factor(y.train$Group)
y.train$Group.detail  = NULL
y.train$V10 = factor(y.train$V10)
set.seed(10)
dfg = y.train$V10
chelix = y.train$Group
y.dfg = y.train
y.dfg[,c(1,2,3,4,7,8)]= NULL
y.train.rf.impute = rfImpute(
x = y.train[,c(2:10)],
y = y.train$Group ,
ntree = 1000)
colnames(y.train.rf.impute)[1] <- 'Group'
head(y.train.rf.impute)
head(y.train.rf.impute)
y.train.rf.dfg = randomForest( V10 ~., data=y.train.rf.impute[,c(2:ncol(y.train.rf.impute))],
ntree = 1000)
y.train.rf.dfg
y.train.rf.dfg$importance
y.train.rf.impute$V10 = y.train$V10
head(y.train.rf.impute)
y.train.rf = randomForest(Group ~.,data = y.train.rf.impute,
ntree = 1000)
y.train.rf
y.test[c(1)]= NULL
head(y.test)
y.test = y[which(y$Group == "")[1]:nrow(y),]
y.test[,c(1)]= NULL
head(y.test)
y.test = y.test[complete.cases(y.test),]
y.test.pred.dfg = as.data.frame(predict(object = y.train.rf.dfg, newdata = y.test, type = "prob"))
y.test.pred.dfg
y.test.dfg = y.test
for (i in 1:nrow(y.test.pred.dfg)) {
col = (which.max(y.test.pred.dfg[i,]))
dfgstat = as.numeric(row.names(as.data.frame(col)))
y.test.dfg[i, 8] = dfgstat
}
colnames(y.test.dfg) = c(colnames(y.test), "V10")
y.test.dfg$V10 = factor(y.test.dfg$V10)
y.test.dfg$Row.names = row.names(y.test.dfg)
y.test.dfg.pred = y.test.dfg
head(y.test.dfg.pred)
y.test.dfg = y.test
for (i in 1:nrow(y.test.pred.dfg)) {
col = (which.max(y.test.pred.dfg[i,]))
dfgstat = as.numeric(row.names(as.data.frame(col)))
y.test.dfg[i, 9] = dfgstat
}
colnames(y.test.dfg) = c(colnames(y.test), "V10")
y.test.dfg$V10 = factor(y.test.dfg$V10)
y.test.dfg$Row.names = row.names(y.test.dfg)
y.test.dfg.pred = y.test.dfg
head(y.test.dfg.pred)
y.test.dfg.pred[,c(1:8)] = NULL
colnames(y.test.dfg.pred) = c("DFGStatus", "Row.names")
y.test.dfg.pred
head(y.test.dfg)
y.test.dfg$Row.names = NULL
y.test.pred = as.data.frame(predict( object = y.train.rf,newdata =  y.test.dfg, type = "prob"))
y.test.pred.class = y.test.pred
head(y.test.pred.class)
for ( i in 1:nrow(y.test.pred))
{
col = which.max(y.test.pred[i,])
y.test.pred.class[i,6] =  as.character(row.names(as.data.frame(col)))
y.test.pred.class[i,7] = as.numeric(y.test.pred[i,col])
}
head(y.test.pred.class)
y.test.pred.class[,1:5] = NULL
colnames(y.test.pred.class) = c("Class", "Probability")
y.predicted.class = merge(y.test.pred.class, y, by="row.names")
y.predicted.class = merge(y.predicted.class, y.test.dfg.pred, by = "Row.names")
head(y.predicted.class)
y.test.pred.class
y.predicted.class = merge(y.test.pred.class, y, by="Row.names")
head(y)
y.predicted.class = merge(y.test.pred.class, y, by="row.names")
head(y.predicted.class)
y.predicted.class = merge(y.predicted.class, y.test.dfg.pred, by = "Row.names")
head(y.predicted.class)
head(y.train)
y.train$Row.names = row.names(y.predicted.class)
y.train$Probablity = rep( "v", nrow(y.train))
y.train
y.train$Row.names = row.names(y.train)
y.train$Probablity = rep( "v", nrow(y.train))
y.predicted.class$Group = NULL
y.predicted.class$Group.detail = NULL
y3 = y.train[,c(10,1,11,2:9)]
colnames(y3) =  colnames(y.predicted.class)
head(y3)
head( y.predicted.class)
y.predicted.class = merge(y.test.pred.class, y, by="row.names")
head(y.test.dfg.pred)
y.predicted.class = merge(y.test.pred.class, y, by="row.names")
y.predicted.class = merge(y.predicted.class, y.test.dfg.pred, by = "row.names")
head(y.predicted.class)
y.predicted.class = merge(y.predicted.class, y.test.dfg.pred, by = "Row.names")
y.predicted.class = merge(y.test.pred.class, y, by="row.names")
y.predicted.class = merge(y.predicted.class, y.test.dfg.pred, by = "Row.names")
head(y.predicted.class)
head(y.train)
head(y.predicted.class)
y3 = y.train[,c(10,1,11,2:9)]
head(y.predicted.class)
head(y.predicted.class,1)
head(y3,1)
head(y.trian,1)
head(y.train,1)
y3 = y.train[,c(12,1,11,2:9)]
head(y.train,1)
head(y3,1)
head(y.predicted.class,1)
y3 = y.train[,c(12,1,11,2:10)]
head(y.predicted.class,1)
head(y3,1)
y.predicted.class$Group = NULL
head(y.predicted.class,1)
head(y3,1)
y.combined = rbind(y3, y.predicted.class)
names(y3) = names(y.predicted.class)
y.combined = rbind(y3, y.predicted.class)
head(y.combined)
tail(y.combined)
View(y.test)
head(y.train)
colors = c("#443333","#cc5522","#00ccff","#AA96DA", "grey50")
library(plotly)
library(ggplot2)
colors = c("#443333","#cc5522","#00ccff","#AA96DA", "grey50")
plot_ly(y.train, x = ~p1p1x, y = ~p2p2x, z = ~h_cgvc, color = Group,
colors = colors,  mode = 'markers', text = ~paste('Id:', Row.names, '<br>Source', source))
plot_ly(y.train, x = ~p1p1x, y = ~p2p2x, z = ~h_cgvc, color = ~Group,
colors = colors,  mode = 'markers', text = ~paste('Id:', Row.names, '<br>Source', source))
head(y.train)
plot_ly(y.train, x = ~p1p1x, y = ~p2p2x, z = ~h_cgvc, color = ~Group,
colors = colors,  mode = 'markers', text = ~paste('Id:', Row.names, '<br>Source', source))
plot_ly(y.train, x = ~p1p1x, y = ~p2p2x, z = ~h_cgvc, color = ~Group,
colors = colors,  mode = 'markers')
head(full.data)
test.chelix.predictions
head(test.chelix.predictions)
head(training.n)
training.n$dfg = training.dfg
training.n$V15 = training.class
training.n$V16 = rep(1, nrow(training))
full.data = as.data.frame(rbind(training.n,test.chelix.predictions))
head(full.data)
full.data[,c(1:10)]
qq = full.data[,c(1:10)]
qq
hclust(dist(qq))
plot(hclust(dist(qq)))
head(qq)
plot(hclust(dist(qq)))
heatmap(qq)
heatmap(data.matrix(qq))
plot_ly(full.data.px.vec, x = ~p1p1x.y, y = ~p2p2x.y, z = ~h_scvc.x, color = ~V18,
colors = colors,  mode = 'markers', text = ~paste('Id:', Row.names, '<br>Source', source))
library(plotly)
library(ggplot2)
plot_ly(full.data.px.vec, x = ~p1p1x.y, y = ~p2p2x.y, z = ~h_scvc.x, color = ~V18,
colors = colors,  mode = 'markers', text = ~paste('Id:', Row.names, '<br>Source', source))
plot_ly(full.data, x = ~p1p1x.y, y = ~p2p2x.y, z = ~h_scvc.x, color = ~V18,
colors = colors,  mode = 'markers', text = ~paste('Id:', Row.names, '<br>Source', source))
plot_ly(full.data, x = ~p1p1x, y = ~p2p2x, z = ~h_scvc, color = ~V18,
colors = colors,  mode = 'markers', text = ~paste('Id:', Row.names, '<br>Source', source))
plot_ly(full.data, x = ~p1p1x, y = ~p2p2x, z = ~h_scvc, color = ~V18,
colors = colors,  mode = 'markers')
plot_ly(full.data, x = ~p1p1x, y = ~p2p2x, z = ~h_scvc,
colors = colors,  mode = 'markers')
head(full.data)
plot_ly(full.data, x = ~p1p1x, y = ~p2p2x, z = ~h_scvc, color = ~V15 ,
colors = colors,  mode = 'markers')
head(tani.sig.kfam)
meta = read.table("../../stdy_kinase.xtal.complete.170601.csv", sep  = ",", header = T)
fam = read.table("../../kinasecom.uniprot.families.2.csv", sep =",", header = F )
head(fam)
colnames(fam) = c("row", "uni_id", 3:ncol(fam))
for ( i in 1:nrow(meta))
{
rw = meta[i,]
id = as.character(rw$uni_id)
fami =as.character(fam[which(fam$uni_id == id),]$`9`)
if ( length(fami) > 0)
{
meta[i,25] = fami
}
else
{
meta[i,25] = "Family_Not_Found"
}
}
meta$Row.names = paste(meta$pdb_id, meta$pdb_ch_id , sep = "_")
full.data.lig.kinase.fam = full.data.lig
for ( i in 1:nrow(full.data.lig.kinase.fam))
{
rw = full.data.lig.kinase.fam[i,]
pdb = as.character(rw$Row.names)
kfam = as.character(meta[meta$Row.names == pdb, ]$V25)
if ( length(kfam) > 0 )
{
full.data.lig.kinase.fam[i,21] = kfam[1]
}
else
{
full.data.lig.kinase.fam[i,21] = "Family_Not_Found"
}
}
full.data.lig.kinase.fam = full.data.lig
full.data.lig = merge(full.data, lig, by = "Row.names")
tani = read.table("../kinase_metrics.v5/../../pdb.ligands.smi.tanimoto.fp.txt.uniq.cases", sep = ",", header = F)
lig = read.table("../../pdb.ligand.smi.csv.complete.cases", sep = ",", header = F)
library(qgraph)
library(tidyr)
lig$V4= NULL
lig$V3= NULL
colnames(lig) = c("Row.names", "Ligand")
full.data.lig = merge(full.data, lig, by = "Row.names")
full.data.lig.kinase.fam = full.data.lig
full.data = as.data.frame(rbind(training.n,test.chelix.predictions))
library(tidyverse)
library(randomForest)
library(plotly)
library(clusterSim)
set.seed(42)
dat = read.table("../../1_manual_classes/stdy_kinase.param.170829.rrahman.csv",header =T, sep ="," )
dat.rel.col = dat[,c(1,4,5,6,7,8,9,10,11,12,13,14,15,16,17,30,33)]
training = dat.rel.col[c(1,3:261),] ## row 1 is duplcate of row 2
row.names(training) = training$pdb_id
training$dfg_st_2 = factor(as.vector(training$dfg_st_2))
training.class = as.factor(as.character(training$Group))
t.c.df = as.data.frame(training.class)
t.c.sp <- separate(t.c.df, training.class, c(paste0("V",LETTERS[1:2])),sep = c(2,4))
training.dfg = training$dfg_st
training[,c(1,2,3,12)] = NULL
test = dat.rel.col[262:nrow(dat.rel.col),]
row.names(test) = test$pdb_id
test[,c(1,2,3,12)] = NULL
test.complete = test[complete.cases(test),]
training.impute = rfImpute(x = training, y = training.class ,   ntree = 1000)
training.impute$training.class = NULL
combined.data = as.data.frame(rbind(training.impute, test.complete))
combined.n = data.Normalization(combined.data,type = "n2", normalization = "column" )
training.n = combined.n[1:260,]
test.n = combined.n[261:nrow(combined.n),]
training.dfg.2 = c()
for (i in 1:length(training.class))
{
if (training.class[i] == "other")
{
training.dfg.2[i] = 3
}
else
{
g = substr(training.class[i], 3, 5 )
if (g == "di") {
training.dfg.2[i] = 1
}
else {
training.dfg.2[i] = 0
}
}
}
training.class = as.factor(t.c.sp[,1])
training.dfg.2 = as.factor(training.dfg.2)
set.seed(10)
training.dfg.rf = randomForest( training.dfg ~., data=training.n,
ntree = 1000)
training.n.dfg = training.n
training.n.dfg$dfg = as.factor(training.dfg) ##add dfg data to data
set.seed(10)
training.chelix.rf = randomForest( training.class ~., data=training.n.dfg,
ntree = 2000)
training.chelix.rf
training.dfg.rf
test.pred.dfg = as.data.frame(predict(object = training.dfg.rf, newdata = test.n, type = "prob"))
test.pred.dfg.2 = test.n
for (i in 1:nrow(test.pred.dfg)) {
col = (which.max(test.pred.dfg[i,]))
dfgstat = as.character(row.names(as.data.frame(col)))
test.pred.dfg.2[i, 14] = dfgstat
}
test.dfg =  test.pred.dfg.2$V14
test.pred.dfg.2$dfg  = test.dfg
test.pred.dfg.2$V14 = NULL
test.pred.dfg.2$dfg = as.factor(test.pred.dfg.2$dfg)
test.chelix.pred = as.data.frame(predict( object = training.chelix.rf, newdata =  test.pred.dfg.2, type = "prob"))
test.chelix.predictions = test.pred.dfg.2
for ( i in 1:nrow(test.chelix.pred))
{
col = which.max(test.chelix.pred[i,])
test.chelix.predictions[i,15] =  as.character(row.names(as.data.frame(col)))
test.chelix.predictions[i,16] = as.numeric(test.chelix.pred[i,col])
}
head(test.chelix.predictions)
head(training.n)
training.n$dfg = training.dfg
training.n$V15 = training.class
training.n$V16 = rep(1, nrow(training))
full.data = as.data.frame(rbind(training.n,test.chelix.predictions))
source = c(rep("training",nrow(training)),rep("test",nrow(test.chelix.predictions)))
full.data$source = source
full.data[,18]  = paste(full.data$V15, full.data$dfg, sep = "-")
full.data[full.data$dfg =="random", 18] = "omega"
tani = read.table("../kinase_metrics.v5/../../pdb.ligands.smi.tanimoto.fp.txt.uniq.cases", sep = ",", header = F)
lig = read.table("../../pdb.ligand.smi.csv.complete.cases", sep = ",", header = F)
library(qgraph)
library(tidyr)
lig$V4= NULL
lig$V3= NULL
colnames(lig) = c("Row.names", "Ligand")
full.data.lig = merge(full.data, lig, by = "Row.names")
head(full.data)
full.data$Row.names = rownames(full.data)
full.data.lig = merge(full.data, lig, by = "Row.names")
lig.conf = full.data.lig[,c(20,19)]
lig.conf
head(lig.conf)
lig.conf.counted = as.data.frame(table(lig.conf))
lig.conf.counted.wide = spread(lig.conf.counted, V18 ,value =  Freq , fill = 0 )
lig.conf.counted.wide
ligand.dominant.class = data.frame()
for (i in 1:nrow(lig.conf.counted.wide))
{
rw = lig.conf.counted.wide[i,]
ligand = as.character(rw$Ligand)
rw$Ligand = NULL
tot = sum(rw)
if (tot == 0)
{
next ;
}
cols = colnames(rw)
for (ii in 1:ncol(rw))
{
freq = rw[,ii] / tot
n = cols[ii]
if ( freq > 0.5 )
{
row = as.data.frame(t(as.data.frame(c(ligand, n, freq))))
ligand.dominant.class  = as.data.frame(rbind(ligand.dominant.class , row))
}
else
{
#row = as.data.frame(t(as.data.frame(c(ligand, "nonspecific" , freq))))
#ligand.dominant.class  = as.data.frame(rbind(ligand.dominant.class , row))
}
}
}
head(full.data.lig)
tani$weight = (tani$V3 *1.2) + (tani$V4*1.2) + (tani$V5 *.6)
tani$z = (tani$weight - mean(tani$weight))/ sd(tani$weight)
tani$p = pnorm(-abs(tani$z))
tani$padj = p.adjust(tani$p, method = "fdr", n = length(tani$p))
tani.sig = tani[which(tani$padj < .1 ), ]
tani.sig = tani.sig[which(tani.sig$weight > mean(tani$weight)) ,]
tani.sig.full = tani.sig
tani.sig[,c(3:6,8:ncol(tani.sig))] = NULL
tani.sig$V1  = as.character(tani.sig$V1)
tani.sig$V2 = as.character(tani.sig$V2)
colnames(ligand.dominant.class) = c("ligand1", "struct", "freq")
for ( i in 1:nrow(tani.sig))
{
rw = tani.sig[i,]
lig = rw$V2
class = as.character(ligand.dominant.class[which(ligand.dominant.class$ligand1 == lig),2])
if ( length(class) == 0)
{
tani.sig[i,4] = "nonspecific"
}
else
{
tani.sig[i,4] = class
print(paste(lig, class, sep = " "))
}
}
head(tani.sig)
write.table(tani.sig, file = "../tani.sig.distance.csv.2" ,sep = ",", quote = F, eol =  "\n", row.names = F )
write.table(tani.sig, file = "../tani.sig.distance.2.csv" ,sep = ",", quote = F, eol =  "\n", row.names = F )
which(tani.sig$V1 %in% tani.sig$V2)
tani.sig(which(tani.sig$V1 %in% tani.sig$V2) )
tani.sig[which(tani.sig$V1 %in% tani.sig$V2),]
nrow(tani.sig)
tani.sig[! which(tani.sig$V1 %in% tani.sig$V2),]
tani.sig[ which(tani.sig$V1 ! %in% tani.sig$V2),]
tani.sig[!which(tani.sig$V1 %in% tani.sig$V2),]
tani.sig[!(tani.sig$V1 %in% tani.sig$V2),]
tani.sig[!(tani.sig$V1 %in% tani.sig$V2),]$V1
unique(tani.sig[!(tani.sig$V1 %in% tani.sig$V2),]$V1)
missing.pdb= unique(tani.sig[!(tani.sig$V1 %in% tani.sig$V2),]$V1)
head(tani.sig)
cbind(missing.pdb, missing.pdb, rep(3,length(missing.pdb), rep("missing", length(missing.pdb))))
as.data.frame(cbind(missing.pdb, missing.pdb, rep(3,length(missing.pdb), rep("missing", length(missing.pdb)))))
as.data.frame(cbind(missing.pdb, missing.pdb, rep(3,length(missing.pdb)), rep("missing", length(missing.pdb))))
rbind(tani.sig,as.data.frame(cbind(missing.pdb, missing.pdb, rep(3,length(missing.pdb)), rep("missing", length(missing.pdb)))))
missing.df = tani.sig,as.data.frame(cbind(missing.pdb, missing.pdb, rep(3,length(missing.pdb)), rep("missing", length(missing.pdb))))
missing.df = as.data.frame(cbind(missing.pdb, missing.pdb, rep(3,length(missing.pdb)), rep("missing", length(missing.pdb))))
colnames(missing.df)= colnames(tani.sig)
rbind(tani.sig,missing.df)
tail(rbind(tani.sig,missing.df))
tani.sig.combined = rbind(tani.sig,missing.df)
tani.sig = tani[which(tani$padj < .1 ), ]
tani.sig = tani.sig[which(tani.sig$weight > mean(tani$weight)) ,]
library(qgraph)
library(tidyr)
tani.sig.full = tani.sig
tani.sig[,c(3:6,8:ncol(tani.sig))] = NULL
tani.sig$V1  = as.character(tani.sig$V1)
tani.sig$V2 = as.character(tani.sig$V2)
colnames(ligand.dominant.class) = c("ligand1", "struct", "freq")
tani.sig
missing.pdb= unique(tani.sig[!(tani.sig$V1 %in% tani.sig$V2),]$V1)
missing.pdb= unique(tani.sig[!(tani.sig$V1 %in% tani.sig$V2),]$V1)
missing.df = as.data.frame(cbind(missing.pdb, missing.pdb, rep(3,length(missing.pdb))))
missing.df
colnames(missing.df)= colnames(tani.sig)
tani.sig.combined = rbind(tani.sig,missing.df)
for ( i in 1:nrow(tani.sig.combined))
{
rw = tani.sig.combined[i,]
lig = rw$V2
class = as.character(ligand.dominant.class[which(ligand.dominant.class$ligand1 == lig),2])
if ( length(class) == 0)
{
tani.sig.combined[i,4] = "nonspecific"
}
else
{
tani.sig.combined[i,4] = class
print(paste(lig, class, sep = " "))
}
}
head(tani.sig.combined)
tail(tani.sig.combined,1000)
tail(tani.sig.combined,100)
write.table(tani.sig.combined, file = "../tani.sig.distance.11.29.2017.no.missing.classes.csv" ,sep = ",", quote = F, eol =  "\n", row.names = F )
